{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9baff11",
   "metadata": {},
   "source": [
    "## AI Foundry Onboarding \n",
    "\n",
    "\n",
    "### Create your AI Foundry Project \n",
    "1. Go to [ai.azure.com](https://ai.azure.com/)\n",
    "2. Create a new Azure AI Project\n",
    "\n",
    "\n",
    "![Creating an AI Project](./images/aifoundry01.png)\n",
    "Click on \"Create\"...\n",
    "\n",
    "![Creating an AI Project02](./images/aifoundry02.png)\n",
    "Choose \"AI Foundry Resource\"...\n",
    "\n",
    "![Creating an AI Project03](./images/aifoundry03.png)\n",
    "You can use any region to create your AI Foundry Project in. \\\n",
    "Make sure the models you would like to use are available in the region of your choice. \\\n",
    "You can use the model availability table named \"Global standard model availability\", in [*\"Azure OpenAI in Azure AI Foundry Models\" documentation*\"](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models?tabs=global-standard%2Cstandard-chat-completions) for checking which models are available in which region. This is continously updated. For the purposes of hackathon sweden-central would have all models we would need to use. \n",
    "\n",
    "\n",
    "![Creating an AI Project04](./images/aifoundry04.png)\n",
    "\n",
    "Once you click on \"create\" your projects starts to be provisioned. It may take 1-2 mins for your project to be ready.\n",
    "\n",
    "![Creating an AI Project05](./images/aifoundry05.png)\n",
    "\n",
    "Once created you will land on your project page with a project key. \n",
    "AI Foundry project key is used when you are using the Foundry SDK which facilitates services integration to AI Foundry such as AI Search. We will not be using Foundry SDK in the workshop. \n",
    "\n",
    "\n",
    "![Creating an AI Project06](./images/aifoundry06.png)\n",
    "\n",
    "Next, we will deploy LLM's on AI Foundry, we will use in our development. \\\n",
    "Choose model catalog and search for gpt-4.1 which is the latest model from openai being offered on Azure OpenAI service replacing gpt-4o. \n",
    "\n",
    "\n",
    "\n",
    "![Creating an AI Project07](./images/aifoundry07.png)\n",
    "\n",
    "Deploy the model...We will not need to change default parameters e.g. model version, quoata or filter so keep them as they are given by default.\n",
    "\n",
    "![Creating an AI Project08](./images/aifoundry08.png)\n",
    "\n",
    "Copy your API key for later use...\n",
    "\n",
    "![Creating an AI Project09](./images/aifoundry09.png)\n",
    "\n",
    "When the model is deployed you will be given code samples as to how to make an API call for LLM generations. Copy your API endpoint from the sample code. \n",
    "\n",
    "![Creating an AI Project10](./images/aifoundry10.png)\n",
    "\n",
    "Repeat the same deployment task for o4-mini, which is a reasoning model we will later use for more sophisticated tasks where \"reasoning\" will be required e.g. checking a received customer contract clause for compliance or for planning e.g. decomposing a complex task into smaller tasks and executing them with another \"workhorse\" model such as gpt-4.1. \\\n",
    "While deploying these models, please keep deployment names simple. e.g. if you are deploying a gpt-4.1 keep the deployment name as \"gpt-4.1\", or if you are deploying o4-mini, keep your deployment name as \"o4-mini\" and the embedding models deployment name as \"text-embedding-3-small\".\n",
    "\n",
    "![Creating an AI Project11](./images/aifoundry11_embedv3.png)\n",
    "\n",
    "Repeat the same model deployment tasks for text-embedding-3-small\n",
    "\n",
    "![Creating an AI Project12](./images/aifoundry12_final_status.png)\n",
    "\n",
    "Once gpt-4.1, o3-mini and embedv3-small are deployed we are good to go. \n",
    "Comfirm successful deployments on Azure AI Foundry \"Models & Assets\" under my-assets...\n",
    "\n",
    "\n",
    "**References**:\n",
    "- [Create a Project under Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/create-projects?tabs=ai-foundry&pivots=fdp-project)\n",
    "- [Quickstart - Get started with Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/quickstarts/get-started-code?tabs=azure-ai-foundry&pivots=fdp-project)\n",
    "- [Microsoft Learn - Azure AI Foundry Training](https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/)\n",
    "\n",
    "\n",
    "\n",
    "### Confirm Operation \n",
    "\n",
    "Next we will send simple API calls to confirm successful operation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fa398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# ── 1. env + client ───────────────────────────────────────────────────────\n",
    "load_dotenv(\".env\")                                  # AZURE_* vars live here\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key        = \"FXT9IYpLqQuFaCZUsIkp2hxjysSG7Oui4JcV5a5s3IpXRgsmgH6LJQQJ99BFACfhMk5XJ3w3AAAAACOGTJO0\",\n",
    "    azure_endpoint = \"https://ozgurguler-1232-resource.cognitiveservices.azure.com/\",\n",
    "    api_version    = \"2024-12-01-preview\",  # e.g. 2024-06-01-preview\n",
    ")\n",
    "DEPLOYMENT = \"gpt-4.1\"       # your model deployment name\n",
    "\n",
    "# ── 2. system-and-user messages ───────────────────────────────────────────\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a concise astrophysics tutor who explains concepts in plain English.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"What is a black hole?\"}\n",
    "]\n",
    "\n",
    "# ── 3. one-shot call ──────────────────────────────────────────────────────\n",
    "response = client.chat.completions.create(\n",
    "    model       = DEPLOYMENT,\n",
    "    messages    = messages,\n",
    "    temperature = 0.7,\n",
    "    max_tokens  = 256,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content.strip())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
