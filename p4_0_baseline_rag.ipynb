{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dbf67af",
   "metadata": {},
   "source": [
    "### 1.0 Create an Azure AI Search Index \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08b01e",
   "metadata": {},
   "source": [
    " #### Vector-Only Index Creation with Azure AI Search\n",
    "\n",
    "This script creates a vector-only index in Azure AI Search using the General Availability (GA) schema introduced in mid-2024. It sets up an index with just two fields:\n",
    "\n",
    "A string-based document ID (used as the primary key)\n",
    "A vector field (contentVector) that holds embedding data (e.g.Azure OpenAI)\n",
    "We configure the vector search behavior to use the HNSW algorithm with cosine similarity, which is ideal for semantic search scenarios. This vector-only setup is lean and optimized for scenarios where we rely purely on vector search (e.g., similarity search in embeddings) rather than keyword-based retrieval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a5d7199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating or updating index 'index01' ‚Ä¶\n",
      "‚úÖ  Vector-only index ready\n"
     ]
    }
   ],
   "source": [
    "# create_index_vector_only.py ‚Äì GA-compatible vector-only index\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SimpleField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    VectorSearchProfile,\n",
    ")\n",
    "\n",
    "# ‚îÄ‚îÄ 1. env ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv()\n",
    "ENDPOINT   = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "ADMIN_KEY  = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "INDEX_NAME = os.getenv(\"AZURE_SEARCH_INDEX_NAME\", \"index01\")\n",
    "\n",
    "# ‚îÄ‚îÄ 2. algorithm + profile (HNSW + cosine) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "algo_cfg = HnswAlgorithmConfiguration(\n",
    "    name=\"hnsw-cosine\",\n",
    "    parameters=HnswParameters(metric=\"cosine\")  # defaults (m=4, ef* etc.)\n",
    ")\n",
    "\n",
    "profile_cfg = VectorSearchProfile(           # ‚Üê referenced by the field\n",
    "    name=\"hnsw-cosine-profile\",\n",
    "    algorithm_configuration_name=\"hnsw-cosine\",\n",
    ")\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[algo_cfg],\n",
    "    profiles=[profile_cfg],\n",
    ")\n",
    "\n",
    "# ‚îÄ‚îÄ 3. schema: key + vector field only ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchField(\n",
    "        name=\"contentVector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=1536,\n",
    "        vector_search_profile_name=\"hnsw-cosine-profile\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=INDEX_NAME,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search,\n",
    ")\n",
    "\n",
    "# ‚îÄ‚îÄ 4. push the index ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "client = SearchIndexClient(endpoint=ENDPOINT, credential=AzureKeyCredential(ADMIN_KEY))\n",
    "print(f\"Creating or updating index '{INDEX_NAME}' ‚Ä¶\")\n",
    "client.create_or_update_index(index)\n",
    "print(\"‚úÖ  Vector-only index ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43add243",
   "metadata": {},
   "source": [
    "‚úÖ Result\n",
    "Once this script runs, you‚Äôll have a minimal, production-ready vector-only index that is compatible with the new GA schema and supports efficient vector similarity search via HNSW and cosine distance.\n",
    "\n",
    "You can now upload vectorized documents and perform semantic search queries efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfecb4fe",
   "metadata": {},
   "source": [
    "### 2.0 OCR the PDF \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53afacb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocumentintelligence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocumentIntelligenceClient\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ SETUP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m SCRIPT_DIR = Path(\u001b[34;43m__file__\u001b[39;49m).resolve().parent           \u001b[38;5;66;03m# current folder\u001b[39;00m\n\u001b[32m     13\u001b[39m load_dotenv(dotenv_path=SCRIPT_DIR / \u001b[33m\"\u001b[39m\u001b[33m.env\u001b[39m\u001b[33m\"\u001b[39m)           \u001b[38;5;66;03m# credentials in .env\u001b[39;00m\n\u001b[32m     15\u001b[39m ENDPOINT = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mDOCUMENTINTELLIGENCE_ENDPOINT\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ocr_single_pdf.py ‚Äì OCR one PDF (2504_IMF_WOO.pdf) with Azure Document Intelligence\n",
    "Outputs 2504_IMF_WOO.txt in the same directory.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ SETUP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "SCRIPT_DIR = Path(__file__).resolve().parent           # current folder\n",
    "load_dotenv(dotenv_path=SCRIPT_DIR / \".env\")           # credentials in .env\n",
    "\n",
    "ENDPOINT = os.getenv(\"DOCUMENTINTELLIGENCE_ENDPOINT\")\n",
    "KEY      = os.getenv(\"DOCUMENTINTELLIGENCE_API_KEY\")\n",
    "if not ENDPOINT or not KEY:\n",
    "    sys.exit(\"‚ùå  Missing DOCUMENTINTELLIGENCE_‚Ä¶ values in .env\")\n",
    "\n",
    "client = DocumentIntelligenceClient(\n",
    "    endpoint=ENDPOINT,\n",
    "    credential=AzureKeyCredential(KEY)\n",
    ")\n",
    "\n",
    "PDF_FILE = SCRIPT_DIR / \"2504_IMF_WOO.pdf\"             # ‚Üê target file\n",
    "if not PDF_FILE.exists():\n",
    "    sys.exit(f\"‚ùó  {PDF_FILE.name} not found in {SCRIPT_DIR.resolve()}\")\n",
    "\n",
    "print(f\"üîç  Processing {PDF_FILE.name} ‚Ä¶\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ OCR ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    with PDF_FILE.open(\"rb\") as fh:\n",
    "        poller = client.begin_analyze_document(\n",
    "            \"prebuilt-read\",                           # model_id\n",
    "            fh,                                        # binary stream\n",
    "            content_type=\"application/pdf\",\n",
    "        )\n",
    "    result = poller.result()\n",
    "\n",
    "    pages_txt = [\n",
    "        \"\\n\".join(ln.content for ln in (p.lines or []))\n",
    "        for p in (result.pages or [])\n",
    "    ]\n",
    "    raw_text = \"\\n\\n\".join(pages_txt)\n",
    "\n",
    "    TXT_OUT = PDF_FILE.with_suffix(\".txt\")\n",
    "    TXT_OUT.write_text(raw_text, encoding=\"utf-8\")\n",
    "    print(f\"‚úÖ  Text saved to {TXT_OUT.name}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Failed to process {PDF_FILE.name}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
